"""
UnivFD (Universal Fake Detector) 기반 AI 생성 이미지 탐지
CLIP ViT-L/14 + Linear Probe를 활용한 딥페이크 감지
"""
import io
import logging
from pathlib import Path

import numpy as np
import torch
import torch.nn as nn
from PIL import Image

from .clip_detector import CLIPDetectionResult

logger = logging.getLogger(__name__)

# Linear probe 가중치 경로
PROBE_PATH = Path(__file__).parent / "deepfake_explainer" / "models" / "univfd_linear_probe.pth"


class UnivFDDetector:
    """UnivFD: CLIP ViT-L/14 + Linear Probe 딥페이크 탐지"""

    def __init__(self):
        self._model = None
        self._preprocess = None
        self._probe = None
        self._device = None
        self._initialized = False
        self._has_probe = False
        # zero-shot 폴백용 프롬프트 (ViT-L/14에 최적화)
        self._prompts = {
            "real": [
                "a real photograph taken by a camera",
                "an authentic unedited photograph",
                "a genuine photo of a real scene",
                "a natural photograph with real lighting",
                "an original unmanipulated photo",
            ],
            "fake": [
                "a fake image generated by artificial intelligence",
                "a deepfake image with synthetic artifacts",
                "an AI-generated image by diffusion model",
                "a GAN-generated synthetic face image",
                "a computer-generated fake photograph",
                "a digitally fabricated image with AI",
                "a neural network generated image",
                "an artificially synthesized deepfake image",
            ],
        }

    def _ensure_initialized(self):
        """모델 초기화 (지연 로딩)"""
        if self._initialized:
            return

        try:
            import ssl
            ssl._create_default_https_context = ssl._create_unverified_context

            import clip

            self._device = "cuda" if torch.cuda.is_available() else "cpu"
            logger.info(f"UnivFD Detector using device: {self._device}")

            # CLIP ViT-L/14 로드 (768차원, B/32보다 정확)
            self._model, self._preprocess = clip.load("ViT-L/14", device=self._device)

            # Linear probe 로드 시도
            if PROBE_PATH.exists():
                self._probe = nn.Linear(768, 1).to(self._device)
                state_dict = torch.load(PROBE_PATH, map_location=self._device, weights_only=True)
                self._probe.load_state_dict(state_dict)
                self._probe.eval()
                self._has_probe = True
                logger.info("UnivFD linear probe loaded successfully")
            else:
                logger.info("UnivFD linear probe not found, using zero-shot fallback")
                # zero-shot 폴백: 텍스트 임베딩 미리 계산
                self._real_text_features = self._encode_texts(self._prompts["real"])
                self._fake_text_features = self._encode_texts(self._prompts["fake"])

            self._initialized = True
            logger.info("UnivFD Detector initialized successfully")

        except ImportError:
            logger.warning("CLIP not installed. Run: pip install git+https://github.com/openai/CLIP.git")
            raise
        except Exception as e:
            logger.error(f"Failed to initialize UnivFD detector: {e}")
            raise

    def _encode_texts(self, texts: list[str]) -> torch.Tensor:
        """텍스트를 CLIP 임베딩으로 변환"""
        import clip
        text_tokens = clip.tokenize(texts).to(self._device)
        with torch.no_grad():
            text_features = self._model.encode_text(text_tokens)
            text_features = text_features / text_features.norm(dim=-1, keepdim=True)
        return text_features

    def analyze(self, image_data: bytes) -> CLIPDetectionResult:
        """이미지 분석"""
        self._ensure_initialized()

        try:
            image = Image.open(io.BytesIO(image_data))
            if image.mode != "RGB":
                image = image.convert("RGB")

            image_input = self._preprocess(image).unsqueeze(0).to(self._device)

            with torch.no_grad():
                image_features = self._model.encode_image(image_input)
                image_features = image_features / image_features.norm(dim=-1, keepdim=True)

            if self._has_probe:
                return self._analyze_with_probe(image_features)
            else:
                return self._analyze_zero_shot(image_features)

        except Exception as e:
            logger.error(f"UnivFD analysis failed: {e}")
            return CLIPDetectionResult(
                is_ai_generated=False,
                confidence=50.0,
                real_score=50.0,
                fake_score=50.0,
                details={"error": str(e)},
            )

    def _analyze_with_probe(self, image_features: torch.Tensor) -> CLIPDetectionResult:
        """Linear probe로 분석"""
        with torch.no_grad():
            logit = self._probe(image_features.float()).squeeze()
            fake_prob = torch.sigmoid(logit).item()

        real_prob = 1.0 - fake_prob
        is_ai_generated = fake_prob > 0.5
        confidence = fake_prob * 100 if is_ai_generated else real_prob * 100

        return CLIPDetectionResult(
            is_ai_generated=is_ai_generated,
            confidence=confidence,
            real_score=real_prob * 100,
            fake_score=fake_prob * 100,
            details={
                "method": "linear_probe",
                "raw_logit": logit.item(),
                "fake_probability": fake_prob * 100,
                "real_probability": real_prob * 100,
            },
        )

    def _analyze_zero_shot(self, image_features: torch.Tensor) -> CLIPDetectionResult:
        """Zero-shot 프롬프트 폴백"""
        real_similarities = (image_features @ self._real_text_features.T).squeeze()
        real_score = real_similarities.mean().item()

        fake_similarities = (image_features @ self._fake_text_features.T).squeeze()
        fake_score = fake_similarities.mean().item()

        scores = torch.tensor([real_score, fake_score])
        probs = torch.softmax(scores * 50, dim=0)

        real_prob = probs[0].item()
        fake_prob = probs[1].item()

        is_ai_generated = fake_prob > 0.5
        confidence = fake_prob * 100 if is_ai_generated else real_prob * 100

        return CLIPDetectionResult(
            is_ai_generated=is_ai_generated,
            confidence=confidence,
            real_score=real_prob * 100,
            fake_score=fake_prob * 100,
            details={
                "method": "zero_shot",
                "raw_real_score": real_score,
                "raw_fake_score": fake_score,
                "real_probability": real_prob * 100,
                "fake_probability": fake_prob * 100,
            },
        )

    def is_available(self) -> bool:
        """서비스 사용 가능 여부"""
        try:
            import clip
            return True
        except ImportError:
            return False


# 싱글톤
_univfd_detector: UnivFDDetector | None = None


def get_univfd_detector() -> UnivFDDetector:
    """UnivFD Detector 싱글톤"""
    global _univfd_detector
    if _univfd_detector is None:
        _univfd_detector = UnivFDDetector()
    return _univfd_detector
